{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9895be63",
   "metadata": {},
   "source": [
    "### Gemini 2.0 flash lite VS Tuned Gemini 2.0 flash lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "766e695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Project root: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON\n",
      "DEBUG: Src path: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/src\n",
      "/home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/src already in sys.path\n",
      "Project modules (config, utils, vllm_handler) imported successfully.\n",
      "Verified: vllm_handler.analyze_content has 'model_id_override' parameter.\n",
      "\n",
      "Setup cell execution complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown # For displaying DataFrames and Markdown\n",
    "import vertexai # Import base vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, FinishReason, Image as VertexImage # Specific imports\n",
    "from google.api_core import exceptions as google_exceptions # For error handling\n",
    "import inspect # To inspect function signature\n",
    "# Import List and Dict for type hinting if needed, though often optional in notebooks\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.getLogger(\"google.api_core\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"google.auth\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"PIL\").setLevel(logging.WARNING)\n",
    "\n",
    "# --- Project Path Setup ---\n",
    "# Notebook is in the project root directory\n",
    "project_root = os.path.abspath('.')\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "\n",
    "print(f\"DEBUG: Project root: {project_root}\")\n",
    "print(f\"DEBUG: Src path: {src_path}\")\n",
    "\n",
    "if os.path.isdir(src_path):\n",
    "    if src_path not in sys.path:\n",
    "        sys.path.insert(0, src_path)\n",
    "        print(f\"Added {src_path} to sys.path\")\n",
    "    else:\n",
    "        print(f\"{src_path} already in sys.path\")\n",
    "else:\n",
    "    print(f\"ERROR: src directory not found at {src_path}. Cannot import project modules.\")\n",
    "    raise FileNotFoundError(f\"src directory not found at {src_path}\")\n",
    "\n",
    "# --- Import project modules ---\n",
    "try:\n",
    "    import config\n",
    "    import utils\n",
    "    # Import the specific functions needed from vllm_handler\n",
    "    from vllm_handler import analyze_content, initialize_vertex_ai\n",
    "    print(\"Project modules (config, utils, vllm_handler) imported successfully.\")\n",
    "\n",
    "    # Verify the handler has the modified function signature\n",
    "    sig = inspect.signature(analyze_content)\n",
    "    if 'model_id_override' not in sig.parameters:\n",
    "         print(\"\\nCRITICAL WARNING: vllm_handler.analyze_content is missing the 'model_id_override' parameter!\")\n",
    "         print(\"Please ensure src/vllm_handler.py is saved with the correct version and RESTART THE KERNEL.\")\n",
    "         # raise AttributeError(\"analyze_content function signature is incorrect.\")\n",
    "    else:\n",
    "         print(\"Verified: vllm_handler.analyze_content has 'model_id_override' parameter.\")\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing project modules from {src_path}: {e}\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred loading config/utils: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nSetup cell execution complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfb83460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Using Input Image Directory: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg\n",
      "\n",
      "Configuration and Helper Functions cell execution complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Configuration & Helper Functions (for Base vs Tuned Comparison)\n",
    "\n",
    "# --- Model Configuration ---\n",
    "BASE_MODEL_ID = \"gemini-2.0-flash-lite-001\"\n",
    "# Your specific fine-tuned model ID\n",
    "TUNED_MODEL_ID = \"projects/248124319532/locations/europe-west4/models/8219698240602243072\"\n",
    "\n",
    "# --- Input/Output Configuration ---\n",
    "# Construct paths relative to project_root (defined in Cell 1)\n",
    "OUTPUT_DIR_PATH = os.path.join(project_root, 'outputs')\n",
    "INPUT_IMAGE_DIR_PATH = os.path.join(project_root, 'inputs', 'jpeg') # Use JPEG input path\n",
    "IMAGE_EXTENSIONS = {\".jpg\", \".jpeg\"} # Focus on jpeg/jpg for this run\n",
    "\n",
    "COMPARISON_OUTPUT_FILENAME = \"comparison_base_vs_tuned_results.json\" # Specific filename\n",
    "GRAPH_OUTPUT_FILENAME = \"comparison_base_vs_tuned_graph.png\"\n",
    "COMPARISON_TABLE_FILENAME = \"comparison_base_vs_tuned_table.csv\"\n",
    "\n",
    "# --- Test Prompt ---\n",
    "TEST_PROMPT = \"Describe this image briefly, focusing on any text present.\"\n",
    "\n",
    "# --- Debugging Print ---\n",
    "print(f\"DEBUG: Using Input Image Directory: {INPUT_IMAGE_DIR_PATH}\")\n",
    "# ---\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)\n",
    "\n",
    "# Store results for this specific comparison run\n",
    "comparison_results_list = [] # Use this list within this notebook run\n",
    "base_model_times = []\n",
    "tuned_model_times = []\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def get_image_files_in_dir(image_input_dir: str) -> List[str]:\n",
    "    \"\"\"Gets a list of absolute paths for specified IMAGE files in the directory.\"\"\"\n",
    "    files = []\n",
    "    abs_image_input_dir = os.path.abspath(image_input_dir)\n",
    "    print(f\"DEBUG: [get_image_files_in_dir] Checking for images in: {abs_image_input_dir}\")\n",
    "\n",
    "    if not os.path.isdir(abs_image_input_dir):\n",
    "        logging.error(f\"Image input directory not found: {abs_image_input_dir}\")\n",
    "        print(f\"ERROR: [get_image_files_in_dir] Image input directory not found: {abs_image_input_dir}\")\n",
    "        return files\n",
    "\n",
    "    logging.info(f\"Scanning for image files in: {abs_image_input_dir}\")\n",
    "    found_count = 0\n",
    "    try:\n",
    "        for filename in os.listdir(abs_image_input_dir):\n",
    "            if filename.startswith('.'): continue\n",
    "            _, file_extension = os.path.splitext(filename.lower())\n",
    "            if file_extension in IMAGE_EXTENSIONS: # Check against specified extensions\n",
    "                full_path = os.path.join(abs_image_input_dir, filename)\n",
    "                if os.path.isfile(full_path):\n",
    "                    files.append(os.path.abspath(full_path))\n",
    "                    found_count += 1\n",
    "                    logging.debug(f\"Found image file: {full_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error listing directory {abs_image_input_dir}: {e}\")\n",
    "        print(f\"ERROR: [get_image_files_in_dir] Error listing directory {abs_image_input_dir}: {e}\")\n",
    "        return []\n",
    "\n",
    "    logging.info(f\"Found {found_count} image files in {abs_image_input_dir}.\")\n",
    "    print(f\"DEBUG: [get_image_files_in_dir] Found {found_count} image files.\")\n",
    "    return files\n",
    "\n",
    "# --- analyze_content_wrapper (uses the imported vllm_handler.analyze_content) ---\n",
    "# This wrapper simplifies calling the function from the main loop and handles timing\n",
    "def analyze_content_wrapper(file_path: str, model_to_use: str) -> tuple[str, float | None]:\n",
    "    \"\"\"\n",
    "    Calls the main analysis function from vllm_handler with timing.\n",
    "    Returns the result string and duration in seconds (or None if error).\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # Ensure Vertex AI is initialized (should be done in Cell 4, but safe to check)\n",
    "        if not initialize_vertex_ai():\n",
    "            return \"Error: Vertex AI Not Initialized\", None\n",
    "\n",
    "        # Call the imported analyze_content function from vllm_handler\n",
    "        result_str = analyze_content(file_path, model_id_override=model_to_use)\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time\n",
    "        # Check if the result indicates an error from within analyze_content\n",
    "        if result_str.startswith(\"Error:\"):\n",
    "             return result_str, None # Return error string, no valid duration\n",
    "        else:\n",
    "             return result_str, duration # Return success string and duration\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error calling analyze_content for {os.path.basename(file_path)} with model {model_to_use}: {e}\", exc_info=True)\n",
    "        return f\"Error: Wrapper exception - {e}\", None\n",
    "\n",
    "\n",
    "print(\"\\nConfiguration and Helper Functions cell execution complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3227e9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 13:50:55,382 - INFO - Scanning for image files in: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg\n",
      "2025-05-03 13:50:55,383 - INFO - Found 5 image files in /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: [get_image_files_in_dir] Checking for images in: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg\n",
      "DEBUG: [get_image_files_in_dir] Found 5 image files.\n",
      "\n",
      "Found 5 image files for comparison.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 3: Get Image Files ---\n",
    "\n",
    "# Use the IMAGE helper function and the specific IMAGE input path (defined in Cell 2)\n",
    "image_files_to_test = get_image_files_in_dir(INPUT_IMAGE_DIR_PATH)\n",
    "\n",
    "if not image_files_to_test:\n",
    "    raise FileNotFoundError(f\"No JPEG/JPG image files found in {INPUT_IMAGE_DIR_PATH}. Please add files to the '{INPUT_IMAGE_DIR_PATH}' directory.\")\n",
    "else:\n",
    "    print(f\"\\nFound {len(image_files_to_test)} image files for comparison.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1ac13b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex AI SDK initialized successfully for comparison.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: Initialize Vertex AI ---\n",
    "\n",
    "# Initialize Vertex AI SDK using the function from vllm_handler (imported in Cell 1)\n",
    "if initialize_vertex_ai():\n",
    "    print(\"Vertex AI SDK initialized successfully for comparison.\")\n",
    "else:\n",
    "    print(\"ERROR: Vertex AI SDK initialization failed. Cannot proceed.\")\n",
    "    # raise RuntimeError(\"Vertex AI SDK failed to initialize.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6af716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 13:50:55,396 - INFO - \n",
      "--- Running Base Model: gemini-2.0-flash-lite-001 ---\n",
      "2025-05-03 13:50:55,398 - INFO - Processing inputs/jpeg/1.jpeg with BASE model...\n",
      "2025-05-03 13:50:55,398 - INFO - Analyzing file: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/1.jpeg\n",
      "2025-05-03 13:50:55,399 - INFO - Processing as MIME type: image/jpeg\n",
      "2025-05-03 13:50:55,418 - ERROR - Failed to load or invalid image file /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/1.jpeg: 'NoneType' object has no attribute 'close'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/src/vllm_handler.py\", line 107, in analyze_content\n",
      "    mime_type = \"text/plain\"\n",
      "  File \"/home/harishi/.local/lib/python3.10/site-packages/PIL/ImageFile.py\", line 172, in verify\n",
      "    self.fp.close()\n",
      "AttributeError: 'NoneType' object has no attribute 'close'\n",
      "2025-05-03 13:50:55,419 - ERROR - Base model error for inputs/jpeg/1.jpeg: Error: Could not load or invalid image file 1.jpeg.\n",
      "2025-05-03 13:50:55,920 - INFO - Processing inputs/jpeg/2.jpeg with BASE model...\n",
      "2025-05-03 13:50:55,921 - INFO - Analyzing file: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/2.jpeg\n",
      "2025-05-03 13:50:55,922 - INFO - Processing as MIME type: image/jpeg\n",
      "2025-05-03 13:50:55,941 - ERROR - Failed to load or invalid image file /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/2.jpeg: 'NoneType' object has no attribute 'close'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/src/vllm_handler.py\", line 107, in analyze_content\n",
      "    mime_type = \"text/plain\"\n",
      "  File \"/home/harishi/.local/lib/python3.10/site-packages/PIL/ImageFile.py\", line 172, in verify\n",
      "    self.fp.close()\n",
      "AttributeError: 'NoneType' object has no attribute 'close'\n",
      "2025-05-03 13:50:55,942 - ERROR - Base model error for inputs/jpeg/2.jpeg: Error: Could not load or invalid image file 2.jpeg.\n",
      "2025-05-03 13:50:56,443 - INFO - Processing inputs/jpeg/3.jpeg with BASE model...\n",
      "2025-05-03 13:50:56,444 - INFO - Analyzing file: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/3.jpeg\n",
      "2025-05-03 13:50:56,445 - INFO - Processing as MIME type: image/jpeg\n",
      "2025-05-03 13:50:56,461 - ERROR - Failed to load or invalid image file /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/3.jpeg: 'NoneType' object has no attribute 'close'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/src/vllm_handler.py\", line 107, in analyze_content\n",
      "    mime_type = \"text/plain\"\n",
      "  File \"/home/harishi/.local/lib/python3.10/site-packages/PIL/ImageFile.py\", line 172, in verify\n",
      "    self.fp.close()\n",
      "AttributeError: 'NoneType' object has no attribute 'close'\n",
      "2025-05-03 13:50:56,463 - ERROR - Base model error for inputs/jpeg/3.jpeg: Error: Could not load or invalid image file 3.jpeg.\n",
      "2025-05-03 13:50:56,964 - INFO - Processing inputs/jpeg/4.jpeg with BASE model...\n",
      "2025-05-03 13:50:56,965 - INFO - Analyzing file: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/4.jpeg\n",
      "2025-05-03 13:50:56,965 - INFO - Processing as MIME type: image/jpeg\n",
      "2025-05-03 13:50:56,980 - ERROR - Failed to load or invalid image file /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/4.jpeg: 'NoneType' object has no attribute 'close'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/src/vllm_handler.py\", line 107, in analyze_content\n",
      "    mime_type = \"text/plain\"\n",
      "  File \"/home/harishi/.local/lib/python3.10/site-packages/PIL/ImageFile.py\", line 172, in verify\n",
      "    self.fp.close()\n",
      "AttributeError: 'NoneType' object has no attribute 'close'\n",
      "2025-05-03 13:50:56,981 - ERROR - Base model error for inputs/jpeg/4.jpeg: Error: Could not load or invalid image file 4.jpeg.\n",
      "2025-05-03 13:50:57,482 - INFO - Processing inputs/jpeg/5.jpeg with BASE model...\n",
      "2025-05-03 13:50:57,482 - INFO - Analyzing file: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/5.jpeg\n",
      "2025-05-03 13:50:57,483 - INFO - Processing as MIME type: image/jpeg\n",
      "2025-05-03 13:50:57,497 - ERROR - Failed to load or invalid image file /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/5.jpeg: 'NoneType' object has no attribute 'close'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/src/vllm_handler.py\", line 107, in analyze_content\n",
      "    mime_type = \"text/plain\"\n",
      "  File \"/home/harishi/.local/lib/python3.10/site-packages/PIL/ImageFile.py\", line 172, in verify\n",
      "    self.fp.close()\n",
      "AttributeError: 'NoneType' object has no attribute 'close'\n",
      "2025-05-03 13:50:57,498 - ERROR - Base model error for inputs/jpeg/5.jpeg: Error: Could not load or invalid image file 5.jpeg.\n",
      "2025-05-03 13:50:57,999 - INFO - Base model run finished. Total time: 2.60s\n",
      "2025-05-03 13:50:58,000 - INFO - Base model: 0 successful, 5 errors.\n",
      "2025-05-03 13:50:58,000 - INFO - \n",
      "--- Running Tuned Model: projects/248124319532/locations/europe-west4/models/8219698240602243072 ---\n",
      "2025-05-03 13:50:58,001 - INFO - Processing inputs/jpeg/1.jpeg with TUNED model...\n",
      "2025-05-03 13:50:58,001 - INFO - Analyzing file: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/1.jpeg\n",
      "2025-05-03 13:50:58,002 - INFO - Processing as MIME type: image/jpeg\n",
      "2025-05-03 13:50:58,019 - ERROR - Failed to load or invalid image file /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/1.jpeg: 'NoneType' object has no attribute 'close'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/src/vllm_handler.py\", line 107, in analyze_content\n",
      "    mime_type = \"text/plain\"\n",
      "  File \"/home/harishi/.local/lib/python3.10/site-packages/PIL/ImageFile.py\", line 172, in verify\n",
      "    self.fp.close()\n",
      "AttributeError: 'NoneType' object has no attribute 'close'\n",
      "2025-05-03 13:50:58,020 - ERROR - Tuned model error for inputs/jpeg/1.jpeg: Error: Could not load or invalid image file 1.jpeg.\n",
      "2025-05-03 13:50:58,521 - INFO - Processing inputs/jpeg/2.jpeg with TUNED model...\n",
      "2025-05-03 13:50:58,521 - INFO - Analyzing file: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/2.jpeg\n",
      "2025-05-03 13:50:58,522 - INFO - Processing as MIME type: image/jpeg\n",
      "2025-05-03 13:50:58,541 - ERROR - Failed to load or invalid image file /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/2.jpeg: 'NoneType' object has no attribute 'close'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/src/vllm_handler.py\", line 107, in analyze_content\n",
      "    mime_type = \"text/plain\"\n",
      "  File \"/home/harishi/.local/lib/python3.10/site-packages/PIL/ImageFile.py\", line 172, in verify\n",
      "    self.fp.close()\n",
      "AttributeError: 'NoneType' object has no attribute 'close'\n",
      "2025-05-03 13:50:58,542 - ERROR - Tuned model error for inputs/jpeg/2.jpeg: Error: Could not load or invalid image file 2.jpeg.\n",
      "2025-05-03 13:50:59,043 - INFO - Processing inputs/jpeg/3.jpeg with TUNED model...\n",
      "2025-05-03 13:50:59,043 - INFO - Analyzing file: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/3.jpeg\n",
      "2025-05-03 13:50:59,045 - INFO - Processing as MIME type: image/jpeg\n",
      "2025-05-03 13:50:59,061 - ERROR - Failed to load or invalid image file /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/3.jpeg: 'NoneType' object has no attribute 'close'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/src/vllm_handler.py\", line 107, in analyze_content\n",
      "    mime_type = \"text/plain\"\n",
      "  File \"/home/harishi/.local/lib/python3.10/site-packages/PIL/ImageFile.py\", line 172, in verify\n",
      "    self.fp.close()\n",
      "AttributeError: 'NoneType' object has no attribute 'close'\n",
      "2025-05-03 13:50:59,062 - ERROR - Tuned model error for inputs/jpeg/3.jpeg: Error: Could not load or invalid image file 3.jpeg.\n",
      "2025-05-03 13:50:59,563 - INFO - Processing inputs/jpeg/4.jpeg with TUNED model...\n",
      "2025-05-03 13:50:59,564 - INFO - Analyzing file: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/4.jpeg\n",
      "2025-05-03 13:50:59,565 - INFO - Processing as MIME type: image/jpeg\n",
      "2025-05-03 13:50:59,581 - ERROR - Failed to load or invalid image file /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/4.jpeg: 'NoneType' object has no attribute 'close'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/src/vllm_handler.py\", line 107, in analyze_content\n",
      "    mime_type = \"text/plain\"\n",
      "  File \"/home/harishi/.local/lib/python3.10/site-packages/PIL/ImageFile.py\", line 172, in verify\n",
      "    self.fp.close()\n",
      "AttributeError: 'NoneType' object has no attribute 'close'\n",
      "2025-05-03 13:50:59,582 - ERROR - Tuned model error for inputs/jpeg/4.jpeg: Error: Could not load or invalid image file 4.jpeg.\n",
      "2025-05-03 13:51:00,083 - INFO - Processing inputs/jpeg/5.jpeg with TUNED model...\n",
      "2025-05-03 13:51:00,083 - INFO - Analyzing file: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/5.jpeg\n",
      "2025-05-03 13:51:00,084 - INFO - Processing as MIME type: image/jpeg\n",
      "2025-05-03 13:51:00,098 - ERROR - Failed to load or invalid image file /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/inputs/jpeg/5.jpeg: 'NoneType' object has no attribute 'close'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/src/vllm_handler.py\", line 107, in analyze_content\n",
      "    mime_type = \"text/plain\"\n",
      "  File \"/home/harishi/.local/lib/python3.10/site-packages/PIL/ImageFile.py\", line 172, in verify\n",
      "    self.fp.close()\n",
      "AttributeError: 'NoneType' object has no attribute 'close'\n",
      "2025-05-03 13:51:00,099 - ERROR - Tuned model error for inputs/jpeg/5.jpeg: Error: Could not load or invalid image file 5.jpeg.\n",
      "2025-05-03 13:51:00,600 - INFO - Tuned model run finished. Total time: 2.60s\n",
      "2025-05-03 13:51:00,601 - INFO - Tuned model: 0 successful, 5 errors.\n",
      "2025-05-03 13:51:00,601 - INFO - \n",
      "Comparison processing finished.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 5: Run Comparison Analysis ---\n",
    "\n",
    "# Use the lists defined in Cell 2\n",
    "# comparison_results_list = [] # Already defined in Cell 2\n",
    "# base_model_times = []\n",
    "# tuned_model_times = []\n",
    "files_processed_base = 0\n",
    "files_processed_tuned = 0\n",
    "files_error_base = 0\n",
    "files_error_tuned = 0\n",
    "\n",
    "if image_files_to_test: # Proceed only if files were found\n",
    "    # --- Run Base Model ---\n",
    "    logging.info(f\"\\n--- Running Base Model: {BASE_MODEL_ID} ---\")\n",
    "    total_start_time_base = time.time()\n",
    "    for file_path in image_files_to_test: # file_path is absolute\n",
    "        relative_path = os.path.relpath(file_path, project_root) # Get path relative to project root\n",
    "        logging.info(f\"Processing {relative_path} with BASE model...\")\n",
    "\n",
    "        # Use the wrapper function defined in Cell 2\n",
    "        result_str_base, duration_base = analyze_content_wrapper(file_path, model_to_use=BASE_MODEL_ID)\n",
    "        files_processed_base += 1\n",
    "\n",
    "        result_entry = {\n",
    "            \"file\": relative_path,\n",
    "            \"base_model_output\": result_str_base,\n",
    "            \"base_model_time_sec\": None,\n",
    "            \"tuned_model_output\": \"N/A\", # Placeholder\n",
    "            \"tuned_model_time_sec\": None, # Placeholder\n",
    "        }\n",
    "\n",
    "        if result_str_base.startswith(\"Error:\") or duration_base is None:\n",
    "            logging.error(f\"Base model error for {relative_path}: {result_str_base}\")\n",
    "            files_error_base += 1\n",
    "        else:\n",
    "            base_model_times.append(duration_base)\n",
    "            result_entry[\"base_model_time_sec\"] = duration_base\n",
    "            logging.info(f\"Base model success for {relative_path} in {duration_base:.2f}s\")\n",
    "\n",
    "        comparison_results_list.append(result_entry) # Add entry even if error occurred\n",
    "        time.sleep(0.5) # Small delay\n",
    "\n",
    "    total_end_time_base = time.time()\n",
    "    logging.info(f\"Base model run finished. Total time: {total_end_time_base - total_start_time_base:.2f}s\")\n",
    "    logging.info(f\"Base model: {files_processed_base - files_error_base} successful, {files_error_base} errors.\")\n",
    "\n",
    "    # --- Run Tuned Model ---\n",
    "    logging.info(f\"\\n--- Running Tuned Model: {TUNED_MODEL_ID} ---\")\n",
    "    total_start_time_tuned = time.time()\n",
    "\n",
    "    # Iterate through the existing results list to update entries\n",
    "    for i in range(len(comparison_results_list)):\n",
    "        entry_to_update = comparison_results_list[i]\n",
    "        relative_path = entry_to_update[\"file\"]\n",
    "        # Reconstruct absolute path - ensure project_root is correct\n",
    "        file_path = os.path.join(project_root, relative_path)\n",
    "\n",
    "        logging.info(f\"Processing {relative_path} with TUNED model...\")\n",
    "\n",
    "        # Use the wrapper function defined in Cell 2\n",
    "        result_str_tuned, duration_tuned = analyze_content_wrapper(file_path, model_to_use=TUNED_MODEL_ID)\n",
    "        files_processed_tuned += 1\n",
    "\n",
    "        # Update the dictionary in the list\n",
    "        entry_to_update[\"tuned_model_output\"] = result_str_tuned\n",
    "        if result_str_tuned.startswith(\"Error:\") or duration_tuned is None:\n",
    "            logging.error(f\"Tuned model error for {relative_path}: {result_str_tuned}\")\n",
    "            files_error_tuned += 1\n",
    "        else:\n",
    "            tuned_model_times.append(duration_tuned)\n",
    "            entry_to_update[\"tuned_model_time_sec\"] = duration_tuned\n",
    "            logging.info(f\"Tuned model success for {relative_path} in {duration_tuned:.2f}s\")\n",
    "        time.sleep(0.5) # Small delay\n",
    "\n",
    "\n",
    "    total_end_time_tuned = time.time()\n",
    "    logging.info(f\"Tuned model run finished. Total time: {total_end_time_tuned - total_start_time_tuned:.2f}s\")\n",
    "    logging.info(f\"Tuned model: {files_processed_tuned - files_error_tuned} successful, {files_error_tuned} errors.\")\n",
    "\n",
    "    logging.info(\"\\nComparison processing finished.\")\n",
    "else:\n",
    "    print(\"Skipping analysis run as no input image files were found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "318beff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full comparison results saved to: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/outputs/comparison_base_vs_tuned_results.json\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 6: Save Full Results to JSON ---\n",
    "\n",
    "# Save the detailed comparison results\n",
    "comparison_output_path = os.path.join(OUTPUT_DIR_PATH, COMPARISON_OUTPUT_FILENAME)\n",
    "if comparison_results_list: # Only save if there are results\n",
    "    try:\n",
    "        with open(comparison_output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(comparison_results_list, f, indent=4, ensure_ascii=False)\n",
    "        print(f\"Full comparison results saved to: {comparison_output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving comparison JSON: {e}\")\n",
    "else:\n",
    "    print(\"No comparison results generated to save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "665d3947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison table saved to: /home/harishi/common_drive/Downloads/projects/GDG_HACKATHON/outputs/comparison_base_vs_tuned_table.csv\n",
      "\n",
      "--- Comparison Results Table (First 5 Rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>base_model_output</th>\n",
       "      <th>base_model_time_sec</th>\n",
       "      <th>tuned_model_output</th>\n",
       "      <th>tuned_model_time_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inputs/jpeg/1.jpeg</td>\n",
       "      <td>Error: Could not load or invalid image file 1.jpeg.</td>\n",
       "      <td>None</td>\n",
       "      <td>Error: Could not load or invalid image file 1.jpeg.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inputs/jpeg/2.jpeg</td>\n",
       "      <td>Error: Could not load or invalid image file 2.jpeg.</td>\n",
       "      <td>None</td>\n",
       "      <td>Error: Could not load or invalid image file 2.jpeg.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inputs/jpeg/3.jpeg</td>\n",
       "      <td>Error: Could not load or invalid image file 3.jpeg.</td>\n",
       "      <td>None</td>\n",
       "      <td>Error: Could not load or invalid image file 3.jpeg.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inputs/jpeg/4.jpeg</td>\n",
       "      <td>Error: Could not load or invalid image file 4.jpeg.</td>\n",
       "      <td>None</td>\n",
       "      <td>Error: Could not load or invalid image file 4.jpeg.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>inputs/jpeg/5.jpeg</td>\n",
       "      <td>Error: Could not load or invalid image file 5.jpeg.</td>\n",
       "      <td>None</td>\n",
       "      <td>Error: Could not load or invalid image file 5.jpeg.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file                                    base_model_output  \\\n",
       "0  inputs/jpeg/1.jpeg  Error: Could not load or invalid image file 1.jpeg.   \n",
       "1  inputs/jpeg/2.jpeg  Error: Could not load or invalid image file 2.jpeg.   \n",
       "2  inputs/jpeg/3.jpeg  Error: Could not load or invalid image file 3.jpeg.   \n",
       "3  inputs/jpeg/4.jpeg  Error: Could not load or invalid image file 4.jpeg.   \n",
       "4  inputs/jpeg/5.jpeg  Error: Could not load or invalid image file 5.jpeg.   \n",
       "\n",
       "  base_model_time_sec                                   tuned_model_output  \\\n",
       "0                None  Error: Could not load or invalid image file 1.jpeg.   \n",
       "1                None  Error: Could not load or invalid image file 2.jpeg.   \n",
       "2                None  Error: Could not load or invalid image file 3.jpeg.   \n",
       "3                None  Error: Could not load or invalid image file 4.jpeg.   \n",
       "4                None  Error: Could not load or invalid image file 5.jpeg.   \n",
       "\n",
       "  tuned_model_time_sec  \n",
       "0                 None  \n",
       "1                 None  \n",
       "2                 None  \n",
       "3                 None  \n",
       "4                 None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Timing Statistics (seconds per successful file) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_model_time_sec</th>\n",
       "      <th>tuned_model_time_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       base_model_time_sec tuned_model_time_sec\n",
       "count                    0                    0\n",
       "unique                   0                    0\n",
       "top                    NaN                  NaN\n",
       "freq                   NaN                  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Cell 7: Create and Display Pandas DataFrame ---\n",
    "\n",
    "if comparison_results_list:\n",
    "    # Convert the list of dictionaries to a Pandas DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_results_list)\n",
    "\n",
    "    # Save the DataFrame to CSV\n",
    "    comparison_table_path = os.path.join(OUTPUT_DIR_PATH, COMPARISON_TABLE_FILENAME)\n",
    "    try:\n",
    "        comparison_df.to_csv(comparison_table_path, index=False)\n",
    "        print(f\"Comparison table saved to: {comparison_table_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving comparison CSV: {e}\")\n",
    "\n",
    "\n",
    "    # Display the first few rows of the DataFrame in the notebook\n",
    "    print(\"\\n--- Comparison Results Table (First 5 Rows) ---\")\n",
    "    pd.set_option('display.max_colwidth', 100)\n",
    "    pd.set_option('display.max_rows', 10)\n",
    "    display(comparison_df.head())\n",
    "\n",
    "    # Display basic stats for timing columns (ignoring NaNs)\n",
    "    print(\"\\n--- Timing Statistics (seconds per successful file) ---\")\n",
    "    timing_stats = comparison_df[['base_model_time_sec', 'tuned_model_time_sec']].dropna().describe()\n",
    "    if not timing_stats.empty:\n",
    "         display(timing_stats)\n",
    "    else:\n",
    "         print(\"No successful timing data available for statistics.\")\n",
    "\n",
    "else:\n",
    "    print(\"No comparison results to display in DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbe247eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No successful runs recorded for the base model.\n",
      "No successful runs recorded for the tuned model.\n",
      "\n",
      "Cannot generate time comparison graph: Insufficient successful runs for one or both models.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 8: Generate and Display Comparison Graph ---\n",
    "\n",
    "# Calculate average times only from successful runs\n",
    "avg_time_base_ms = None\n",
    "avg_time_tuned_ms = None\n",
    "\n",
    "if base_model_times:\n",
    "    avg_time_base_ms = (sum(base_model_times) / len(base_model_times)) * 1000 # Convert to ms\n",
    "    print(f\"Average Time Base Model (Successful Runs): {avg_time_base_ms:.2f} ms ({len(base_model_times)} files)\")\n",
    "else:\n",
    "    print(\"No successful runs recorded for the base model.\")\n",
    "\n",
    "if tuned_model_times:\n",
    "    avg_time_tuned_ms = (sum(tuned_model_times) / len(tuned_model_times)) * 1000 # Convert to ms\n",
    "    print(f\"Average Time Tuned Model (Successful Runs): {avg_time_tuned_ms:.2f} ms ({len(tuned_model_times)} files)\")\n",
    "else:\n",
    "    print(\"No successful runs recorded for the tuned model.\")\n",
    "\n",
    "\n",
    "# Plotting only if both models had successful runs\n",
    "if avg_time_base_ms is not None and avg_time_tuned_ms is not None:\n",
    "    # Use more descriptive labels\n",
    "    models = [f'Base\\n({BASE_MODEL_ID})', f'Tuned\\n(...{TUNED_MODEL_ID[-12:]})'] # Show last part of tuned ID\n",
    "    avg_times = [avg_time_base_ms, avg_time_tuned_ms]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    bars = ax.bar(models, avg_times, color=['skyblue', 'lightgreen'])\n",
    "    ax.set_ylabel('Average Time per Image (ms)')\n",
    "    ax.set_title('Base vs. Tuned Model Speed Comparison (Avg. Time for Successful Analyses)')\n",
    "    ax.set_ylim(0, max(avg_times) * 1.2)\n",
    "\n",
    "    # Add text labels to bars\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.0f} ms', va='bottom', ha='center', fontsize=9)\n",
    "\n",
    "    # Save the graph\n",
    "    graph_path = os.path.join(OUTPUT_DIR_PATH, GRAPH_OUTPUT_FILENAME)\n",
    "    try:\n",
    "        plt.savefig(graph_path)\n",
    "        print(f\"\\nComparison graph saved to: {graph_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving comparison graph: {e}\")\n",
    "\n",
    "    # Display the plot inline in the notebook\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"\\nCannot generate time comparison graph: Insufficient successful runs for one or both models.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
